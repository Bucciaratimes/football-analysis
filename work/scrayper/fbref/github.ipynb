{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://github.com/doughagey/FBRef/blob/master/fbref_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Use requests to get the FPL data from the fbref website and put it into a Pandas Dataframe\n",
    "def webscraper(league, passing_url,shooting_url, misc_url):\n",
    "    try:\n",
    "        print('Scraping data for',league)\n",
    "        \n",
    "        # Scrape data from passing URL\n",
    "        print('    Scraping Passing Table')\n",
    "        page_source = requests.get(passing_url)\n",
    "        page_replace_open_tag = page_source.text.replace('<!--\\n   <div class=\"table_outer_container\"','<div class =\"table_outer_container\">')\n",
    "        page_good_tags = page_replace_open_tag.replace('</div>\\n-->','</div>')\n",
    "        passing_df = pd.read_html(page_good_tags, header=1)[1]\n",
    "        print('        Found',len(passing_df.columns),'columns of data')\n",
    "        if len(passing_df.columns)<3 and len(passing_df.columns)>0:\n",
    "            print('    Was not able to load table')\n",
    "\n",
    "\n",
    "        # Scrape data from shooting URL\n",
    "        print('    Scraping Shooting Table')\n",
    "        page_source = requests.get(shooting_url)\n",
    "        page_replace_open_tag = page_source.text.replace('<!--\\n   <div class=\"table_outer_container\"','<div class =\"table_outer_container\">')\n",
    "        page_good_tags = page_replace_open_tag.replace('</div>\\n-->','</div>')\n",
    "        shooting_df = pd.read_html(page_good_tags)[1]\n",
    "        print('        Found',len(shooting_df.columns),'columns of data')\n",
    "        if len(shooting_df.columns)<3 and len(shooting_df.columns)>0:\n",
    "            print('    Was not able to load table')\n",
    "\n",
    "        #Scrape data from misc URL\n",
    "        print('    Scraping Misc Table')\n",
    "        # This page also has an additional header we need to ignore\n",
    "        page_source = requests.get(misc_url)\n",
    "        page_replace_open_tag = page_source.text.replace('<!--\\n   <div class=\"table_outer_container\"','<div class =\"table_outer_container\">')\n",
    "        page_good_tags = page_replace_open_tag.replace('</div>\\n-->','</div>')\n",
    "        misc_df = pd.read_html(page_good_tags, header=1)[1]\n",
    "        print('        Found',len(misc_df.columns),'columns of data')\n",
    "        if len(misc_df.columns)<3 and len(misc_df.columns)>0:\n",
    "            print('    Was not able to load table')\n",
    "\n",
    "        # Rename the df columns to something more useful by using a map vs. just renaming, which is dangerous if things move around\n",
    "        passing_df = passing_df.rename(columns={'Pos':'Position','Ast':'Assists','A-xA':'Assists-xA','KP':'KeyPasses','Left':'Passes With LF', 'Right':'Passes with RF', 'FK':'Free Kick Passes', 'TB':'Through Ball Passes', 'CK':'Corner Kicks', 'TI':'Throw Ins', '1/3':'Passes into final third', 'PPA':'Passes Into Penalty Box', 'CrsPA':'Crosses into Penalty Box'})\n",
    "        passing_df = passing_df[passing_df.Player != 'Player']\n",
    "        # Get rid of the rows that have NaN as they are bogus and don't relate to players\n",
    "        passing_df = passing_df.fillna(0)\n",
    "        #print(passing_df.head(5))\n",
    "        shooting_df = shooting_df.rename(columns={'Pos':'Position','Gls':'Goals','Sh':'Shots Total','FK':'FK Shots','SoT':'Shots on Target', 'FK':'FK Shots','SoT%':'Shots on Target %','Sh/90':'Shots per 90','SoT/90':'SOT per 90','G/Sh':'Goals per Shot','G/SoT':'Goals per SOT','npxG/Sh':'npxG per Shot','G-xG':'Goals minus xG','np:G-xG':'np Goals minus xG'})\n",
    "        # Passing df has names that are duplicates because the top row was chopped off earlier, needed to rename them to clarify\n",
    "        passing_df = passing_df.rename(columns={'Cmp.1':'Short Passes Completed','Att.1':'Short Attempted Passes','Cmp%.1':'Short Passes Completed%','Cmp.2':'Medium Passes Completed','Att.2':'Medium Passes Attempted','Cmp%.2':'Medium Passes Completed%','Cmp.3':'Long Passes Completed','Att.3':'Long Passes Attempted','Cmp%.3':'Long Passes Completed%','Cmp':'Total Passes Completed','Att':'Total Passes Attempted','Cmp%':'Total Passes Completed%'})\n",
    "        shooting_df = shooting_df[shooting_df.Player != 'Player']\n",
    "        misc_df = misc_df.rename(columns={'Pos':'Position','Fls':'FoulsCommitted','Fld':'FoulsDrawn','Off':'Offsides','Crs':'Crosses', 'TklW':'SuccessfulTackles','Int':'Interceptions','Succ':'SuccessfulDribbles','Att':'AttemptedDribbles','Succ%':'SuccessfulDribbles%','#Pl':'PlayersDribbledPast','Megs':'Nutmegs','Tkl':'DribblersTackled','Att.1':'DribblesContested','Tkl%':'%DribblersTackled','Past':'DribbledPastByOpponent'})\n",
    "        misc_df = misc_df[misc_df.Player != 'Player']\n",
    "\n",
    "        # Get rid of the rows that have NaN as they are bogus and don't relate to players\n",
    "        shooting_df = shooting_df.fillna(0)\n",
    "        \n",
    "        #Replace Position indentifiers with something more useful\n",
    "        shooting_df['Position'] = shooting_df['Position'].str.slice(0,2)\n",
    "        position_map = {'DF':'DEF', 'FW':'FWD', 'MF':'MID'}\n",
    "        shooting_df = shooting_df.replace({'Position': position_map})\n",
    "        passing_df= passing_df.replace({'Position': position_map})\n",
    "        \n",
    "        #Drop the duplicate columns before merging\n",
    "        passing_df.drop(['Nation', 'Position','Squad', 'Age', 'Born', '90s','Matches'], axis=1, inplace=True)\n",
    "        shooting_df.drop(['Matches'], axis=1, inplace=True)\n",
    "        misc_df.drop(['Nation', 'Position','Squad', 'Age', 'Born', '90s','Matches'], axis=1, inplace=True)\n",
    "\n",
    "        #Merge the dataframes so that we have all the info together - on requires a list in brackets\n",
    "        EPL_player_df = pd.merge(shooting_df, passing_df, on=['Rk','Player'])\n",
    "        EPL_player_df = pd.merge(EPL_player_df, misc_df, on=['Rk','Player'])\n",
    "        #print(EPL_player_df.head(5))\n",
    "        \n",
    "        # Export to .csv so we can use in tableau]\n",
    "        print('Writing csv file for',league)\n",
    "        EPL_player_df.to_csv('FBRef_'+league+'_Player_Data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "print('Which league do you want to scrape FBRef.com for?')\n",
    "print('1 - English Premier League')\n",
    "print('2 - La Liga')\n",
    "print('3 - Bundesliga')\n",
    "print('4 - Serie A')\n",
    "print('5 - Ligue 1')\n",
    "print('6 - Champions League')\n",
    "league = input('Type a single league number or hit enter for all leagues:')\n",
    "\n",
    "if len(league)<1:\n",
    "    EPL = webscraper('EPL', 'https://fbref.com/en/comps/9/passing/Premier-League-Stats', 'https://fbref.com/en/comps/9/shooting/Premier-League-Stats','https://fbref.com/en/comps/9/misc/Premier-League-Stats')\n",
    "    LaLiga = webscraper('LaLiga', 'https://fbref.com/en/comps/12/passing/La-Liga-Stats','https://fbref.com/en/comps/12/shooting/La-Liga-Stats','https://fbref.com/en/comps/12/misc/La-Liga-Stats')\n",
    "    Bundesliga = webscraper('BundesLiga', 'https://fbref.com/en/comps/20/passing/Bundesliga-Stats', 'https://fbref.com/en/comps/20/shooting/Bundesliga-Stats','https://fbref.com/en/comps/20/misc/Bundesliga-Stats')\n",
    "    SerieA = webscraper('SerieA', 'https://fbref.com/en/comps/11/passing/Serie-A-Stats', 'https://fbref.com/en/comps/11/shooting/Serie-A-Stats','https://fbref.com/en/comps/11/misc/Serie-A-Stats')\n",
    "    Ligue1 = webscraper('Ligue1', 'https://fbref.com/en/comps/13/passing/Ligue-1-Stats', 'https://fbref.com/en/comps/13/shooting/Ligue-1-Stats','https://fbref.com/en/comps/13/misc/Ligue-1-Stats')\n",
    "    ChampionsLeague = webscraper('ChampionsLeague', 'https://fbref.com/en/comps/8/passing/Champions-League-Stats', 'https://fbref.com/en/comps/8/shooting/Champions-League-Stats','https://fbref.com/en/comps/8/misc/Champions-League-Stats')\n",
    "elif league == '1':\n",
    "    EPL = webscraper('EPL', 'https://fbref.com/en/comps/9/passing/Premier-League-Stats', 'https://fbref.com/en/comps/9/shooting/Premier-League-Stats','https://fbref.com/en/comps/9/misc/Premier-League-Stats')\n",
    "elif league == '2':\n",
    "    LaLiga = webscraper('LaLiga', 'https://fbref.com/en/comps/12/passing/La-Liga-Stats','https://fbref.com/en/comps/12/shooting/La-Liga-Stats','https://fbref.com/en/comps/12/misc/La-Liga-Stats')\n",
    "elif league == '3':\n",
    "    Bundesliga = webscraper('BundesLiga', 'https://fbref.com/en/comps/20/passing/Bundesliga-Stats', 'https://fbref.com/en/comps/20/shooting/Bundesliga-Stats','https://fbref.com/en/comps/20/misc/Bundesliga-Stats')\n",
    "elif league == '4':\n",
    "    SerieA = webscraper('SerieA', 'https://fbref.com/en/comps/11/passing/Serie-A-Stats', 'https://fbref.com/en/comps/11/shooting/Serie-A-Stats','https://fbref.com/en/comps/11/misc/Serie-A-Stats')\n",
    "elif league == '5':\n",
    "    Ligue1 = webscraper('Ligue1', 'https://fbref.com/en/comps/13/passing/Ligue-1-Stats', 'https://fbref.com/en/comps/13/shooting/Ligue-1-Stats','https://fbref.com/en/comps/13/misc/Ligue-1-Stats')\n",
    "elif league == '6':\n",
    "    ChampionsLeague = webscraper('ChampionsLeague', 'https://fbref.com/en/comps/8/passing/Champions-League-Stats', 'https://fbref.com/en/comps/8/shooting/Champions-League-Stats','https://fbref.com/en/comps/8/misc/Champions-League-Stats')\n",
    "else:\n",
    "    print('Invalid value selected!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
